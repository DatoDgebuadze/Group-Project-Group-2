{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ce060-7b0d-4b01-bf53-d4ba360d86f6",
   "metadata": {},
   "source": [
    "# COMP2006: Group Project\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To successfully complete this project, you need to collect and process data, then train and evaluate at least two machine learning models and lastly deploy them to a website. Please see below for further details:\n",
    "\n",
    "> Python (or a python package) is to be used everywhere it possibly can!\n",
    "\n",
    "**Data Collection**\n",
    "\n",
    "Data can be collected (legally) from anywhere. You may use data that you already have; or from sites that allow you to download the data, for example, [UCI Machine Learning Repository](https://archive.ics.uci.edu/) or [Kaggle Datasets](https://www.kaggle.com/datasets); or via web scraping; or via an API. We can restrict ourselves to data that would fit nicely into a spreadsheet. The content and amount of data are not the main consideration, as long as the data has:\n",
    "- at least 10 variables\n",
    "- three or more data types\n",
    "- two or more problems: missing data, inconsistencies, errors, categorical data that needs to be converted to numeric, entries like text that need to be converted into proper features, etc. \n",
    "- if the data does not have enough problems, you can substitute one problem for feature engineering (creating new features from the original features)\n",
    "\n",
    "We are not concerned with acquiring *huge* datasets or creating super accurate models, but more with the process of creating a proper pipeline for machine learning and, for any model deployed, having a reliable estimate of its performance. Although, some effort should go into improving an initial model. \n",
    "\n",
    "How many datasets do you need?\n",
    " - Groups of 2 need **two** datasets\n",
    " - Group of 3 needs **three** datasets\n",
    "\n",
    "**Database**\n",
    "\n",
    "After the data has been collected and processed, it should be stored in a SQLite database. At a minimum, each dataset should have its own table. Database and table creation and data insertion can be done either with the `sqlite3` package or with `Pandas`. Both SQLite and `sqlite3` come with Python. \n",
    "\n",
    "**Machine Learning Models**\n",
    "\n",
    "For each dataset you should train, evaluate, and save a machine learning model:\n",
    "- one model should be for a *classification* problem\n",
    "- the other model should be for a *regression* problem\n",
    "- Group of 3: you should have 2 of one type\n",
    "\n",
    "A *validation* dataset must be used to either select between models, or to choose between hyperparameter values of a single model. \n",
    "\n",
    "A *test* dataset must be used to evaluate the performance of the final chosen model. \n",
    "\n",
    "**Website**\n",
    "\n",
    "The final models should be presented to an end-user through a website. (Deployment need only be to *localhost*). The website must be done using a Python \"web framework\", e.g., *flask*, *Django*, *streamlit*.  \n",
    "\n",
    "The website should have:\n",
    " - a *Welcome* page that describes your project\n",
    " - an *About* page for each dataset that provides:\n",
    "     - the source of the dataset\n",
    "     - definition of each variable in the dataset\n",
    "     - a view of a sample of the dataset used for training (pulled from the database)\n",
    " - a page for each machine learning model that:\n",
    "    - identifies the model being used, with a brief description\n",
    "    - allows the end-user to enter their own data to get a prediction\n",
    "\n",
    "**Readme.md**\n",
    "\n",
    "This file should present the reader with a basic description of your project and how they can use it. \n",
    "\n",
    "**Requirements.txt**\n",
    "\n",
    "This file contains all packages necessary to run your code. This file should allow the user to install all necessary packages via the command: `pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "## Structure\n",
    "\n",
    "- All project related code in a single Github repository\n",
    "- All code in the repository is only FINAL code\n",
    "- The repository structure is\n",
    "    - main folder\n",
    "        - data collection \n",
    "        - data processing \n",
    "        - database\n",
    "        - models\n",
    "            - model 1\n",
    "            - model 2\n",
    "            - model 3 (if required)\n",
    "        - website\n",
    "        - Readme.md\n",
    "        - requirements.txt\n",
    "- Each subfolder should be logically organized\n",
    "\n",
    "## Submission\n",
    "\n",
    "Submission consists of uploading a link to the Github repository containing all the code for your project. There should be one submission per group. \n",
    "\n",
    "Example: `https://github.com/markcassar/COMP2006_project_Group_8`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a4e2c-4fbb-4ab2-a073-bb21b65f1e4f",
   "metadata": {},
   "source": [
    "## Security\n",
    "Using an API is still allowed, just not required. If you choose to use an API, then \n",
    "\n",
    "> please DO NOT include your API Key in your GitHub repository\n",
    "\n",
    "You will be creating a public GitHub repository for your project, which means anyone can access and use your any code or data that is in it. Many API providers will require you to register and create an API Key. When accessing data through the API, you need to authenticate using your API Key before any data will be returned from an API call. \n",
    "\n",
    "To keep you API Key(s) safe, please do the following:\n",
    " - create a `credentials.py` file that stores the value of your key(s) in Python variables\n",
    " - add `credentials.py` to the `.gitignore` file of your repository so GitHub does not automatically track any changes to this file\n",
    " - in your code, you can access your keys via import:\n",
    " \n",
    " ```python\n",
    " import credentials\n",
    " \n",
    " weather_api_key = credentials.weather_api_key\n",
    " ```\n",
    "In this way, anyone accessing your GitHub repository will not be able to access your personal API account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f4a094a-cde8-43bc-9677-e131b1e8c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16176470588235295\n",
      "      Year  Home Score  Away Score\n",
      "0   1960.0         0.0         3.0\n",
      "1   1960.0         4.0         5.0\n",
      "2   1960.0         0.0         2.0\n",
      "3   1960.0         2.0         1.0\n",
      "4   1964.0         0.0         3.0\n",
      "5   1964.0         2.0         1.0\n",
      "6   1964.0         3.0         1.0\n",
      "7   1964.0         2.0         1.0\n",
      "8   1968.0         0.0         1.0\n",
      "9   1968.0         0.0         0.0\n",
      "10  1968.0         2.0         0.0\n",
      "11  1968.0         1.0         1.0\n",
      "12  1968.0         2.0         0.0\n",
      "13  1972.0         1.0         2.0\n",
      "14  1972.0         0.0         1.0\n",
      "15  1972.0         2.0         1.0\n",
      "16  1972.0         3.0         0.0\n",
      "17  1976.0         NaN         1.0\n",
      "18  1976.0         NaN         4.0\n",
      "19  1976.0         2.0         3.0\n",
      "20  1976.0         2.0         2.0\n",
      "21  1980.0         0.0         1.0\n",
      "22  1980.0         1.0         0.0\n",
      "23  1980.0         1.0         1.0\n",
      "24  1980.0         0.0         0.0\n",
      "25  1980.0         3.0         2.0\n",
      "26  1980.0         1.0         3.0\n",
      "27  1980.0         2.0         1.0\n",
      "28  1980.0         1.0         0.0\n",
      "29  1980.0         0.0         0.0\n",
      "30  1980.0         1.0         1.0\n",
      "31  1980.0         0.0         0.0\n",
      "32     NaN         1.0         2.0\n",
      "33  1980.0         1.0         1.0\n",
      "34  1980.0         1.0         2.0\n",
      "35  1984.0         1.0         0.0\n",
      "36  1984.0         2.0         0.0\n",
      "37  1984.0         0.0         0.0\n",
      "38  1984.0         1.0         1.0\n",
      "39     NaN         5.0         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# Load the dataset\n",
    "euros_read_file = pd.read_csv(\"euros.csv\")\n",
    " \n",
    "# Define base features and target variable\n",
    "target = 'Winning Team'\n",
    " \n",
    "# Drop the 'Date' column\n",
    "euros_read_file.drop(columns=['Date'], inplace=True)\n",
    "\n",
    " \n",
    "# Createing missing values in all numeric columns\n",
    "missing_percentage = 0.05  # 5% missing in all numeric features here\n",
    "for column in euros_read_file.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    num_missing = int(len(euros_read_file) * missing_percentage)\n",
    "    missing_indices = euros_read_file[column].sample(n=num_missing).index\n",
    "    euros_read_file.loc[missing_indices, column] = np.nan\n",
    " \n",
    " \n",
    "dataframe_numeric_features = euros_read_file.select_dtypes(include=['int64', 'float64'])\n",
    " \n",
    "# Splitting data into features and target.\n",
    "X = dataframe_numeric_features\n",
    "y = euros_read_file[target]\n",
    " \n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# decided to use randomForestClassifier with 150 decision trees\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "# Display the updated DataFrame\n",
    "print(dataframe_numeric_features.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564561b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0aeba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Home Score  Away Score\n",
      "0    1960.0         0.0         3.0\n",
      "1    1960.0         4.0         5.0\n",
      "2    1960.0         0.0         2.0\n",
      "3    1960.0         2.0         1.0\n",
      "4    1964.0         0.0         3.0\n",
      "..      ...         ...         ...\n",
      "332  2021.0         1.0         2.0\n",
      "333  2021.0         0.0         4.0\n",
      "334  2021.0         1.0         1.0\n",
      "335  2021.0         2.0         1.0\n",
      "336  2021.0         1.0         1.0\n",
      "\n",
      "[337 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "euros_read_file = pd.read_csv(\"euros.csv\")\n",
    "\n",
    "dataframe_numeric_features.fillna(0, inplace=True)\n",
    "\n",
    "print(dataframe_numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15991146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year        Date       Home Team       Away Team  Home Score  Away Score  \\\n",
      "0    1960  1960-07-06  Czechoslovakia          Russia         0.0         3.0   \n",
      "1    1960  1960-07-06          France      Yugoslavia         4.0         5.0   \n",
      "2    1960  1960-07-09          France  Czechoslovakia         0.0         2.0   \n",
      "3    1960  1960-07-10          Russia      Yugoslavia         2.0         1.0   \n",
      "4    1964  1964-06-17         Denmark          Russia         0.0         3.0   \n",
      "..    ...         ...             ...             ...         ...         ...   \n",
      "332  2021  2021-07-03  Czech Republic         Denmark         1.0         2.0   \n",
      "333  2021  2021-07-03         Ukraine         England         0.0         4.0   \n",
      "334  2021  2021-07-06           Italy           Spain         1.0         1.0   \n",
      "335  2021  2021-07-07         England         Denmark         2.0         1.0   \n",
      "336  2021  2021-07-11         England           Italy         1.0         1.0   \n",
      "\n",
      "     Shootout Tournament       City  Country  Neutral Venue    Winning Team  \\\n",
      "0       False  UEFA Euro  Marseille        5           True          Russia   \n",
      "1       False  UEFA Euro      Paris        5          False      Yugoslavia   \n",
      "2       False  UEFA Euro  Marseille        5          False  Czechoslovakia   \n",
      "3       False  UEFA Euro      Paris        5           True          Russia   \n",
      "4       False  UEFA Euro  Barcelona       15           True          Russia   \n",
      "..        ...        ...        ...      ...            ...             ...   \n",
      "332     False  UEFA Euro       Baku        1           True         Denmark   \n",
      "333     False  UEFA Euro       Rome        8           True         England   \n",
      "334      True  UEFA Euro     London        4           True           Italy   \n",
      "335     False  UEFA Euro     London        4          False         England   \n",
      "336      True  UEFA Euro     London        4          False           Italy   \n",
      "\n",
      "    first_shooter     Losing Team  \n",
      "0             NaN  Czechoslovakia  \n",
      "1             NaN          France  \n",
      "2             NaN          France  \n",
      "3             NaN      Yugoslavia  \n",
      "4             NaN         Denmark  \n",
      "..            ...             ...  \n",
      "332           NaN  Czech Republic  \n",
      "333           NaN         Ukraine  \n",
      "334         Italy           Spain  \n",
      "335           NaN         Denmark  \n",
      "336         Italy         England  \n",
      "\n",
      "[337 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    " \n",
    "# Read the CSV file into a DataFrame\n",
    "euros_read_file = pd.read_csv(\"euros.csv\")\n",
    " \n",
    "# will convert the country column from non numeric to numeric\n",
    "euros_read_file['Country'] = euros_read_file['Country'].astype('category').cat.codes\n",
    " \n",
    "print(euros_read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4d0d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17647058823529413\n"
     ]
    }
   ],
   "source": [
    "combined_features = pd.concat([euros_read_file, dataframe_numeric_features], axis=1)\n",
    "\n",
    "X = dataframe_numeric_features\n",
    "y = euros_read_file[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# decided to use randomForestClassifier with 150 decision trees\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# Re evaluation Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c0b20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# fuel_read_file = pd.read_csv(\"my2024-fuel-consumption-ratings 1.csv\")\n",
    "\n",
    "# print(fuel_read_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
