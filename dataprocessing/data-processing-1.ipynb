{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ce060-7b0d-4b01-bf53-d4ba360d86f6",
   "metadata": {},
   "source": [
    "# COMP2006: Group Project\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To successfully complete this project, you need to collect and process data, then train and evaluate at least two machine learning models and lastly deploy them to a website. Please see below for further details:\n",
    "\n",
    "> Python (or a python package) is to be used everywhere it possibly can!\n",
    "\n",
    "**Data Collection**\n",
    "\n",
    "Data can be collected (legally) from anywhere. You may use data that you already have; or from sites that allow you to download the data, for example, [UCI Machine Learning Repository](https://archive.ics.uci.edu/) or [Kaggle Datasets](https://www.kaggle.com/datasets); or via web scraping; or via an API. We can restrict ourselves to data that would fit nicely into a spreadsheet. The content and amount of data are not the main consideration, as long as the data has:\n",
    "- at least 10 variables\n",
    "- three or more data types\n",
    "- two or more problems: missing data, inconsistencies, errors, categorical data that needs to be converted to numeric, entries like text that need to be converted into proper features, etc. \n",
    "- if the data does not have enough problems, you can substitute one problem for feature engineering (creating new features from the original features)\n",
    "\n",
    "We are not concerned with acquiring *huge* datasets or creating super accurate models, but more with the process of creating a proper pipeline for machine learning and, for any model deployed, having a reliable estimate of its performance. Although, some effort should go into improving an initial model. \n",
    "\n",
    "How many datasets do you need?\n",
    " - Groups of 2 need **two** datasets\n",
    " - Group of 3 needs **three** datasets\n",
    "\n",
    "**Database**\n",
    "\n",
    "After the data has been collected and processed, it should be stored in a SQLite database. At a minimum, each dataset should have its own table. Database and table creation and data insertion can be done either with the `sqlite3` package or with `Pandas`. Both SQLite and `sqlite3` come with Python. \n",
    "\n",
    "**Machine Learning Models**\n",
    "\n",
    "For each dataset you should train, evaluate, and save a machine learning model:\n",
    "- one model should be for a *classification* problem\n",
    "- the other model should be for a *regression* problem\n",
    "- Group of 3: you should have 2 of one type\n",
    "\n",
    "A *validation* dataset must be used to either select between models, or to choose between hyperparameter values of a single model. \n",
    "\n",
    "A *test* dataset must be used to evaluate the performance of the final chosen model. \n",
    "\n",
    "**Website**\n",
    "\n",
    "The final models should be presented to an end-user through a website. (Deployment need only be to *localhost*). The website must be done using a Python \"web framework\", e.g., *flask*, *Django*, *streamlit*.  \n",
    "\n",
    "The website should have:\n",
    " - a *Welcome* page that describes your project\n",
    " - an *About* page for each dataset that provides:\n",
    "     - the source of the dataset\n",
    "     - definition of each variable in the dataset\n",
    "     - a view of a sample of the dataset used for training (pulled from the database)\n",
    " - a page for each machine learning model that:\n",
    "    - identifies the model being used, with a brief description\n",
    "    - allows the end-user to enter their own data to get a prediction\n",
    "\n",
    "**Readme.md**\n",
    "\n",
    "This file should present the reader with a basic description of your project and how they can use it. \n",
    "\n",
    "**Requirements.txt**\n",
    "\n",
    "This file contains all packages necessary to run your code. This file should allow the user to install all necessary packages via the command: `pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "## Structure\n",
    "\n",
    "- All project related code in a single Github repository\n",
    "- All code in the repository is only FINAL code\n",
    "- The repository structure is\n",
    "    - main folder\n",
    "        - data collection \n",
    "        - data processing \n",
    "        - database\n",
    "        - models\n",
    "            - model 1\n",
    "            - model 2\n",
    "            - model 3 (if required)\n",
    "        - website\n",
    "        - Readme.md\n",
    "        - requirements.txt\n",
    "- Each subfolder should be logically organized\n",
    "\n",
    "## Submission\n",
    "\n",
    "Submission consists of uploading a link to the Github repository containing all the code for your project. There should be one submission per group. \n",
    "\n",
    "Example: `https://github.com/markcassar/COMP2006_project_Group_8`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a4e2c-4fbb-4ab2-a073-bb21b65f1e4f",
   "metadata": {},
   "source": [
    "## Security\n",
    "Using an API is still allowed, just not required. If you choose to use an API, then \n",
    "\n",
    "> please DO NOT include your API Key in your GitHub repository\n",
    "\n",
    "You will be creating a public GitHub repository for your project, which means anyone can access and use your any code or data that is in it. Many API providers will require you to register and create an API Key. When accessing data through the API, you need to authenticate using your API Key before any data will be returned from an API call. \n",
    "\n",
    "To keep you API Key(s) safe, please do the following:\n",
    " - create a `credentials.py` file that stores the value of your key(s) in Python variables\n",
    " - add `credentials.py` to the `.gitignore` file of your repository so GitHub does not automatically track any changes to this file\n",
    " - in your code, you can access your keys via import:\n",
    " \n",
    " ```python\n",
    " import credentials\n",
    " \n",
    " weather_api_key = credentials.weather_api_key\n",
    " ```\n",
    "In this way, anyone accessing your GitHub repository will not be able to access your personal API account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4a094a-cde8-43bc-9677-e131b1e8c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16176470588235295\n",
      "      Year  Home Score  Away Score\n",
      "0   1960.0         0.0         3.0\n",
      "1   1960.0         4.0         5.0\n",
      "2   1960.0         0.0         2.0\n",
      "3   1960.0         2.0         1.0\n",
      "4   1964.0         0.0         3.0\n",
      "5   1964.0         2.0         NaN\n",
      "6   1964.0         3.0         1.0\n",
      "7   1964.0         2.0         1.0\n",
      "8   1968.0         0.0         NaN\n",
      "9   1968.0         0.0         0.0\n",
      "10     NaN         NaN         0.0\n",
      "11  1968.0         1.0         1.0\n",
      "12  1968.0         2.0         0.0\n",
      "13  1972.0         1.0         2.0\n",
      "14  1972.0         NaN         1.0\n",
      "15  1972.0         2.0         1.0\n",
      "16  1972.0         3.0         0.0\n",
      "17  1976.0         3.0         1.0\n",
      "18  1976.0         2.0         4.0\n",
      "19  1976.0         2.0         3.0\n",
      "20  1976.0         2.0         2.0\n",
      "21  1980.0         0.0         1.0\n",
      "22  1980.0         1.0         NaN\n",
      "23  1980.0         1.0         1.0\n",
      "24  1980.0         0.0         0.0\n",
      "25  1980.0         3.0         2.0\n",
      "26  1980.0         1.0         3.0\n",
      "27  1980.0         2.0         1.0\n",
      "28  1980.0         1.0         0.0\n",
      "29  1980.0         0.0         0.0\n",
      "30  1980.0         1.0         1.0\n",
      "31  1980.0         0.0         0.0\n",
      "32     NaN         1.0         2.0\n",
      "33  1980.0         1.0         1.0\n",
      "34  1980.0         1.0         2.0\n",
      "35  1984.0         1.0         0.0\n",
      "36  1984.0         2.0         0.0\n",
      "37  1984.0         0.0         0.0\n",
      "38  1984.0         1.0         1.0\n",
      "39  1984.0         5.0         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sqlite3\n",
    "# Load the dataset\n",
    "euros_read_file = pd.read_csv(\"../dataset/euros.csv\")\n",
    "conn = sqlite3.connect('../database/pd_data.db')\n",
    "\n",
    "# Define base features and target variable\n",
    "target = 'Winning Team'\n",
    " \n",
    "# Drop the 'Date' column\n",
    "euros_read_file.drop(columns=['Date'], inplace=True)\n",
    " \n",
    "#Createing missing values in all numeric columns\n",
    "missing_percentage = 0.05  # 5% missing in all numeric features here\n",
    "for column in euros_read_file.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    num_missing = int(len(euros_read_file) * missing_percentage)\n",
    "    missing_indices = euros_read_file[column].sample(n=num_missing).index\n",
    "    euros_read_file.loc[missing_indices, column] = np.nan\n",
    " \n",
    " \n",
    "dataframe_numeric_features = euros_read_file.select_dtypes(include=['int64', 'float64'])\n",
    " \n",
    "# Splitting data into features and target.\n",
    "X = dataframe_numeric_features\n",
    "y = euros_read_file[target]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# decided to use randomForestClassifier with 150 decision trees\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "# Display the updated DataFrame\n",
    "print(dataframe_numeric_features.head(40))\n",
    "\n",
    "euros_read_file.to_sql('pd_euros', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "# conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29e15e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "first_shooter\n",
      "Italy             6\n",
      "England           3\n",
      "Spain             3\n",
      "Netherlands       2\n",
      "Switzerland       2\n",
      "Czechoslovakia    1\n",
      "Denmark           1\n",
      "France            1\n",
      "Sweden            1\n",
      "Croatia           1\n",
      "Portugal          1\n",
      "Name: count, dtype: int64\n",
      "Year               int64\n",
      "Date               int16\n",
      "Home Team           int8\n",
      "Away Team           int8\n",
      "Home Score       float64\n",
      "Away Score       float64\n",
      "Shootout            bool\n",
      "Tournament          int8\n",
      "City                int8\n",
      "Country             int8\n",
      "Neutral Venue       bool\n",
      "Winning Team        int8\n",
      "first_shooter       int8\n",
      "Losing Team         int8\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\Desktop\\ML\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40079016681299384\n",
      "     Year  Date  Home Team  Away Team  Home Score  Away Score  Shootout  \\\n",
      "51   1988    36          8         31         2.0         3.0     False   \n",
      "10   1968     8          9         26         2.0         0.0     False   \n",
      "281  2016   161         12         16         1.0         1.0      True   \n",
      "29   1980    21         13         12         0.0         0.0     False   \n",
      "268  2016   155         15          2         2.0         1.0     False   \n",
      "92   1996    61          9         27         2.0         0.0     False   \n",
      "303  2021   172         18          2         2.0         0.0     False   \n",
      "127  2000    78          3         34         0.0         2.0     False   \n",
      "112  2000    70         11          8         3.0         0.0     False   \n",
      "87   1996    58         33          5         0.0         1.0     False   \n",
      "306  2021   173         31         29         1.0         0.0     False   \n",
      "197  2008   117         22         12         2.0         3.0     False   \n",
      "242  2016   146          3         16         0.0         2.0     False   \n",
      "54   1988    38         12          8         2.0         0.0     False   \n",
      "328  2021   182          9         12         2.0         0.0     False   \n",
      "154  2004    92          4          8         0.0         2.0     False   \n",
      "42   1984    29         22         31         1.0         1.0     False   \n",
      "185  2008   111         16         25         1.0         1.0     False   \n",
      "235  2016   143         11         25         2.0         1.0     False   \n",
      "310  2021   175         16         36         1.0         0.0     False   \n",
      "298  2021   171         33         36         0.0         2.0     False   \n",
      "240  2016   145         21         20         1.0         0.0     False   \n",
      "301  2021   172          8          3         1.0         2.0     False   \n",
      "221  2012   132         21          6         0.0         1.0     False   \n",
      "275  2016   157         12         29         3.0         0.0     False   \n",
      "286  2021   166         16         34         3.0         0.0     False   \n",
      "43   1984    30          8          3         3.0         2.0     False   \n",
      "96   1996    63          9         18         4.0         1.0     False   \n",
      "131  2000    80          8          6         0.0         2.0     False   \n",
      "63   1988    43         25         16         2.0         0.0     False   \n",
      "\n",
      "     Tournament  City  Country  Neutral Venue  Winning Team  first_shooter  \\\n",
      "51            1    35        7           True            29              0   \n",
      "10            1    64        9           True            10              0   \n",
      "281           1    11        6           True            13              6   \n",
      "29            1    76        9           True             9              0   \n",
      "268           1    67        6           True            16              0   \n",
      "92            1    46        5          False            10              0   \n",
      "303           1     1       10          False            18              0   \n",
      "127           1    14        3          False            32              0   \n",
      "112           1    13        3           True            12              0   \n",
      "87            1    60        5           True             5              0   \n",
      "306           1    66       14           True            30              0   \n",
      "197           1     7       18           True            13              0   \n",
      "242           1    48        6           True            17              0   \n",
      "54            1    29        7          False            13              0   \n",
      "328           1    46        5          False            10              0   \n",
      "154           1    12       12           True             8              0   \n",
      "42            1    52        6           True             9              0   \n",
      "185           1    82       18           True             9              0   \n",
      "235           1    67        6          False            12              0   \n",
      "310           1    64        9          False            17              0   \n",
      "298           1     5        2           True            34              0   \n",
      "240           1    58        6           True            21              0   \n",
      "301           1    21        4          False             3              0   \n",
      "221           1    80       11          False             6              0   \n",
      "275           1    78        6           True            13              0   \n",
      "286           1    64        9          False            17              0   \n",
      "43            1    73        6           True             8              0   \n",
      "96            1    46        5          False            10              0   \n",
      "131           1    45        3           True             6              0   \n",
      "63            1    74        7           True            25              0   \n",
      "\n",
      "     Losing Team  \n",
      "51             8  \n",
      "10            27  \n",
      "281           17  \n",
      "29             9  \n",
      "268            2  \n",
      "92            28  \n",
      "303            2  \n",
      "127            3  \n",
      "112            8  \n",
      "87            35  \n",
      "306           30  \n",
      "197           24  \n",
      "242            3  \n",
      "54             8  \n",
      "328           13  \n",
      "154            4  \n",
      "42             9  \n",
      "185            9  \n",
      "235           26  \n",
      "310           37  \n",
      "298           35  \n",
      "240           21  \n",
      "301            8  \n",
      "221           23  \n",
      "275           30  \n",
      "286           35  \n",
      "43             3  \n",
      "96            19  \n",
      "131            8  \n",
      "63            17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas.api.types import is_string_dtype, CategoricalDtype\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    " # is_categorical_dtype this is deprecated\n",
    "# Load the dataset\n",
    "\n",
    "conn = sqlite3.connect('../database/pd_data.db')\n",
    "read_file1 = pd.read_csv(\"../dataset/euros.csv\")\n",
    " \n",
    "# Define base features and target variable\n",
    "target = 'Winning Team'\n",
    "# dataframe_numeric_features = read_file1.select_dtypes(include=['int64', 'float64'])\n",
    " \n",
    "# Normalize missing values\n",
    "read_file1.fillna(np.nan, inplace=True)\n",
    "\n",
    "# print(read_file1)\n",
    "\"\"\"\n",
    "The category codes start with 0 and the code for “not a number” (nan) is -1. To bring everything into the range 0 or above, we add one to the category code. (Sklearn has equivalent functionality in its OrdinalEncoder transformer but it can't handle object columns with both integers and strings, plus it's get an error for missing values represented as np.nan.)\n",
    "\"\"\"\n",
    "print(len(read_file1['first_shooter'].unique()))    \n",
    "first_shooter_counts = read_file1['first_shooter'].value_counts()\n",
    "\n",
    "print(first_shooter_counts)\n",
    "#To label encode any categorical variable, convert the column to an ordered categorical variable and then convert the strings to the associated categorical code (which is computed automatically by Pandas):\n",
    "\n",
    "read_file1['first_shooter'] = read_file1['first_shooter'].astype('category').cat.as_ordered()\n",
    "read_file1['first_shooter'] = read_file1['first_shooter'].cat.codes + 1\n",
    "# count of which countries took first shoots and how many times, this seems to be a nominal variable\n",
    "# so i am thinking how to encode them 12 countries with number of times they did first shoot\n",
    "\n",
    "# Convert string columns to categorical and ordinal encode\n",
    "# Loop through each column and check if it's a string dtype\n",
    "for col in read_file1.columns:\n",
    "    if is_string_dtype(read_file1[col]):\n",
    "        read_file1[col] = read_file1[col].astype('category').cat.as_ordered()\n",
    "        \n",
    "for col in read_file1.columns:\n",
    "    if isinstance(read_file1[col].dtype, pd.CategoricalDtype):\n",
    "        read_file1[col] = read_file1[col].cat.codes + 1\n",
    "allfeatures = [col for col in read_file1.columns.tolist()]\n",
    "# checking all the features for the dataset, i am trying to encode first \n",
    "#shooter with other stuff\n",
    "\n",
    "\n",
    "# print(allfeatures)\n",
    "# Check value counts of each class\n",
    "# print(read_file1.head(30))\n",
    " \n",
    "# Separate features and target variable\n",
    "X = read_file1.drop(target, axis=1)  # Features\n",
    "y = read_file1[target]  # Target variable\n",
    " \n",
    "\n",
    "# Checking data types of all columns\n",
    "print(read_file1.dtypes)\n",
    "\n",
    "read_file1 = read_file1.sample(frac=1) # shuffle data\n",
    "read_file1_dev, read_file1_test = train_test_split(read_file1, test_size=0.15)\n",
    "read_file1_train, read_file1_valid = train_test_split(read_file1_dev, test_size=0.15)\n",
    "\"\"\"\n",
    "A slight variation on this procedure is called k-fold cross validation and splits the dataset into k chunks of equal size. We train the model on k-1 chunks and test it on the other, repeating the procedure k times so that we every chunk gets used as a validation set, as shown in Figure\n",
    "\"\"\"\n",
    "#https://mlbook.explained.ai/bulldozer-testing.html\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestClassifier (n_estimators=100, max_depth=10, random_state=42)\n",
    "scores = cross_val_score(rf, X, y, cv=5) \n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "print(read_file1.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9600d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e564561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "euros_read_file = pd.read_csv(\"../dataset/euros.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0aeba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Home Score  Away Score\n",
      "0    1960.0         0.0         3.0\n",
      "1    1960.0         4.0         5.0\n",
      "2    1960.0         0.0         2.0\n",
      "3    1960.0         2.0         1.0\n",
      "4    1964.0         0.0         3.0\n",
      "..      ...         ...         ...\n",
      "332  2021.0         1.0         2.0\n",
      "333  2021.0         0.0         4.0\n",
      "334  2021.0         1.0         1.0\n",
      "335  2021.0         2.0         0.0\n",
      "336  2021.0         1.0         1.0\n",
      "\n",
      "[337 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataframe_numeric_features.fillna(0, inplace=True)\n",
    "\n",
    "print(dataframe_numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15991146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_19584\\1179292920.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(euros_read_file[col]):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_categorical_dtype\n",
    "# for some reason is categorical dtype has this issues though they are talking on depricating\n",
    "# this in next feature this should be working for now\n",
    "# \n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "# Assuming euros_read_file is your DataFrame\n",
    "\n",
    "# Loop through each column and check if it's a string dtype\n",
    "for col in euros_read_file.columns:\n",
    "    if is_string_dtype(euros_read_file[col]):\n",
    "        euros_read_file[col] = euros_read_file[col].astype('category').cat.as_ordered()\n",
    "\n",
    "# Loop through each column and check if it's a categorical dtype\n",
    "for col in euros_read_file.columns:\n",
    "    if is_categorical_dtype(euros_read_file[col]):\n",
    "        euros_read_file[col] = euros_read_file[col].cat.codes + 1\n",
    "\n",
    "# Check unique values before and after conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3921e204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Year  Date  Home Team  Away Team  Home Score  Away Score  Shootout  \\\n",
       "0    1960     1          7         26         0.0         3.0     False   \n",
       "1    1960     1         11         37         4.0         5.0     False   \n",
       "2    1960     2         11          7         0.0         2.0     False   \n",
       "3    1960     3         25         37         2.0         1.0     False   \n",
       "4    1964     4          8         26         0.0         3.0     False   \n",
       "..    ...   ...        ...        ...         ...         ...       ...   \n",
       "332  2021   184          6          8         1.0         2.0     False   \n",
       "333  2021   184         34          9         0.0         4.0     False   \n",
       "334  2021   185         16         31         1.0         1.0      True   \n",
       "335  2021   186          9          8         2.0         1.0     False   \n",
       "336  2021   187          9         16         1.0         1.0      True   \n",
       "\n",
       "     Tournament  City  Country  Neutral Venue  Winning Team first_shooter  \\\n",
       "0             1    52        6           True            25           NaN   \n",
       "1             1    61        6          False            35           NaN   \n",
       "2             1    52        6          False             7           NaN   \n",
       "3             1    61        6           True            25           NaN   \n",
       "4             1     6       16           True            25           NaN   \n",
       "..          ...   ...      ...            ...           ...           ...   \n",
       "332           1     5        2           True             8           NaN   \n",
       "333           1    64        9           True            10           NaN   \n",
       "334           1    46        5           True            17         Italy   \n",
       "335           1    46        5          False            10           NaN   \n",
       "336           1    46        5          False            17         Italy   \n",
       "\n",
       "     Losing Team  \n",
       "0              7  \n",
       "1             12  \n",
       "2             12  \n",
       "3             38  \n",
       "4              8  \n",
       "..           ...  \n",
       "332            6  \n",
       "333           36  \n",
       "334           32  \n",
       "335            8  \n",
       "336           10  \n",
       "\n",
       "[337 rows x 14 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euros_read_file.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d0d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14705882352941177\n"
     ]
    }
   ],
   "source": [
    "combined_features = pd.concat([euros_read_file, dataframe_numeric_features], axis=1)\n",
    "target = 'Winning Team'\n",
    "X = dataframe_numeric_features\n",
    "y = euros_read_file[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# decided to use randomForestClassifier with 150 decision trees\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "# print(y_pred)\n",
    "# Re evaluation Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0b20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# fuel_read_file = pd.read_csv(\"my2024-fuel-consumption-ratings 1.csv\")\n",
    "\n",
    "# print(fuel_read_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
